{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "# Turn inFile into a one hot label\n",
    "def createOneHot(inFile,amountOfClasses):\n",
    "    outFile = np.zeros((inFile.shape[0],inFile.shape[1], amountOfClasses));\n",
    "    for i in range(0,inFile.shape[0]):\n",
    "        for j in range(0,inFile.shape[1]):\n",
    "            #if inFile[i,j] != 0:\n",
    "            outFile[i,j,int(inFile[i,j])] = 1;\n",
    "    return outFile;\n",
    "\n",
    "# Turn 41 orthomosaics into one array. From 1 path with Bands 1 to 41\n",
    "def loadOneOrthomosaic(imagePath):\n",
    "    temp= np.asarray( Image.open( imagePath + 'Band1.png') );\n",
    "    inputData = np.zeros(( temp.shape[0], temp.shape[1], inputChannels),dtype=np.dtype('uint8'))\n",
    "    inputData[:,:,0] = temp[:,:]\n",
    "    for i in range(1,41):\n",
    "        temp= np.asarray( Image.open( imagePath + 'Band' + str(i+1) + '.png') );\n",
    "        inputData[:,:,i] = temp[:,:];\n",
    "    return np.expand_dims( inputData, axis=0)\n",
    "\n",
    "# Load one label from a .mat\n",
    "def loadOneLabel(imagePath):\n",
    "    temp = sio.loadmat(imagePath);\n",
    "    trainOneHotLabels =  createOneHot( temp['labeledPicture'], amountOfClasses);\n",
    "    return np.expand_dims( trainOneHotLabels, axis=0)\n",
    "\n",
    "# Read training data and labels for an array of path tuples, returns (data,labels)\n",
    "def readSet(paths):\n",
    "    numberOfImages = len(paths);\n",
    "    data = np.zeros( (numberOfImages,imageSize[1],imageSize[0],inputChannels), dtype=np.dtype('uint8'));\n",
    "    labels = np.zeros((numberOfImages,imageSize[1],imageSize[0],amountOfClasses), dtype=np.dtype('uint8'))\n",
    "    for i in range(0,numberOfImages):\n",
    "        data[i,:,:,:] = loadOneOrthomosaic(paths[i][0]);\n",
    "        labels[i,:,:,:] = loadOneLabel(paths[i][1]);\n",
    "    return data,labels\n",
    "\n",
    "def oneHotToBinary(oneHotLabel,threshold):\n",
    "    temp = np.zeros((oneHotLabel.shape[1],oneHotLabel.shape[2]), dtype=np.dtype('uint8') );\n",
    "    for i in range(0,oneHotLabel.shape[1]):\n",
    "        for j in range(0,oneHotLabel.shape[2]):\n",
    "            #temp[i,j] = np.argmax(oneHotLabel[0,i,j,:]) + 1;\n",
    "            if np.argmax(oneHotLabel[0,i,j,:])>threshold:\n",
    "                temp[i,j] = np.argmax(oneHotLabel[0,i,j,:])\n",
    "    return temp\n",
    "\n",
    "def predictAndSaveOneImage(inPath,outPath,FCNmodel,threshold):\n",
    "    testImage = loadOneOrthomosaic(inPath);\n",
    "    testLabelPredict = FCNmodel.predict(testImage);\n",
    "    testLabelPredictBinary = oneHotToBinary(testLabelPredict,threshold);\n",
    "    sio.savemat(outPath, mdict={'testLabelPredict': testLabelPredictBinary});\n",
    "\n",
    "def predictAndSaveSet(pathArray, FCNmodel,threshold):\n",
    "    numberOfImages = len(pathArray);\n",
    "    for i in range(0,numberOfImages):\n",
    "        predictAndSaveOneImage(pathArray[i][0], pathArray[i][1], FCNmodel,threshold)\n",
    "        print('Saved ' + pathArray[i][1])\n",
    "        \n",
    "def plotImage(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "def getTrainPaths(paths):\n",
    "    folders = ['FIP','Ximea_Tamron']\n",
    "    fullPath = []\n",
    "    for imageType in paths:\n",
    "        for date in imageType:\n",
    "            temp = []\n",
    "            temp.append(basePath+'trainData/'+folders[paths.index(imageType)]+'/'+date+'/')\n",
    "            temp.append(basePath+'trainLabels/'+folders[paths.index(imageType)]+'_'+date+'.mat') \n",
    "            fullPath.append(temp)\n",
    "    return fullPath\n",
    "    \n",
    "def getTestPaths(paths):\n",
    "    folders = ['FIP','Ximea_Tamron']\n",
    "    fullPath = []\n",
    "    for imageType in paths:\n",
    "        for date in imageType:\n",
    "            temp = []\n",
    "            temp.append(basePath+'testData/'+folders[paths.index(imageType)]+'/'+date+'/')\n",
    "            temp.append(basePath+'testLabelPredict/'+folders[paths.index(imageType)]+'_'+date+'.mat') \n",
    "            fullPath.append(temp)\n",
    "    return fullPath\n",
    "\n",
    "def getSampleWeight(label):\n",
    "    sampleWeights = np.zeros((label.shape[0],label.shape[1]))\n",
    "    counter = np.zeros(amountOfClasses)\n",
    "    numberOfElements = label.shape[0]*label.shape[1]\n",
    "    for i in range(0,label.shape[0]):\n",
    "        for j in range(0,label.shape[1]):\n",
    "            counter[ np.argmax(label[i,j]) ] += 1\n",
    "    for i in range(0,label.shape[0]):\n",
    "        for j in range(0,label.shape[1]):\n",
    "            if counter[np.argmax(label[i,j])] != 0:\n",
    "                sampleWeights[i,j] =  numberOfElements / counter[np.argmax(label[i,j])]\n",
    "    return sampleWeights\n",
    "\n",
    "def getSampleWeights(labels):\n",
    "    sampleWeightArray = np.zeros((labels.shape[0],labels.shape[1],labels.shape[2]))\n",
    "    for i in range(labels.shape[0]):\n",
    "        sampleWeightArray[i,:,:] = getSampleWeight(labels[i,:,:,:])\n",
    "    return sampleWeightArray\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "A weighted version of categorical_crossentropy for keras (2.0.6). This lets you apply a weight to unbalanced classes.\n",
    "@url: https://gist.github.com/wassname/ce364fddfc8a025bfab4348cf5de852d\n",
    "@author: wassname\n",
    "\"\"\"\n",
    "from keras import backend as K\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = getSampleWeights(trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1600, 1600)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data paths\n",
    "basePath = '/Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/';\n",
    "\n",
    "trainSets = [\n",
    "    #FIP\n",
    "    [\n",
    "        '20170622'\n",
    "    ],\n",
    "    #Ximea_Tamron\n",
    "    [\n",
    "        '20170510',\n",
    "        '20170622'\n",
    "    ]\n",
    "]\n",
    "\n",
    "validationSets = [\n",
    "    #FIP\n",
    "    [\n",
    "        '20170531'\n",
    "    ],\n",
    "    #Ximea_Tamron\n",
    "    [\n",
    "    ]\n",
    "]\n",
    "\n",
    "testSets = [\n",
    "    #FIP\n",
    "    [\n",
    "        '20170531', \n",
    "        '20170622',\n",
    "        '20170531_cropped',\n",
    "        '20170622_cropped',\n",
    "        '20170802'\n",
    "    ],\n",
    "    #Ximea_Tamron\n",
    "    [\n",
    "        '20170510',\n",
    "        '20170622',\n",
    "        '20170510_cropped',\n",
    "        '20170622_cropped',\n",
    "        '20170613'\n",
    "    ]\n",
    "]\n",
    "    \n",
    "trainPaths = getTrainPaths(trainSets)\n",
    "validationPaths = getTrainPaths(validationSets)\n",
    "testPaths = getTestPaths(testSets)\n",
    "\n",
    "# Data parameters\n",
    "amountOfClasses = 9;\n",
    "inputChannels = 41;\n",
    "imageSize = [1600,1600]; # [X,Y]\n",
    "\n",
    "numberOfEpochs = 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1600, 1600, 4 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1600, 1600, 6 23680       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 1600, 1600, 6 36928       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 800, 800, 64) 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 800, 800, 128 73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 800, 800, 128 147584      conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 400, 400, 128 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 400, 400, 256 295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 400, 400, 256 590080      conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 400, 256 0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 800, 800, 256 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 800, 800, 128 131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 800, 800, 256 0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 800, 800, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 800, 800, 128 147584      conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 1600, 1600, 1 0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 1600, 1600, 6 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1600, 1600, 1 0           conv2d_27[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 1600, 1600, 6 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 1600, 1600, 6 36928       conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 1600, 1600, 9 585         conv2d_29[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,885,257\n",
      "Trainable params: 1,885,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Cropping2D, UpSampling2D,concatenate,Dropout\n",
    "\n",
    "#crop1 = Cropping2D(cropping=((0, 0), (0, 0)))(conv1) # cropping=((Top, Bottom), (Left, Right))\n",
    "\n",
    "model_inputs = Input(shape=(imageSize[0], imageSize[1], inputChannels))\n",
    "\n",
    "conv1 = Conv2D(64,3, activation='relu', padding='same')(model_inputs)\n",
    "conv1 = Conv2D(64,3, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')(conv1)\n",
    "\n",
    "conv2 = Conv2D(128,3, activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(128,3, activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')(conv2)\n",
    "\n",
    "conv3 = Conv2D(256,3, activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(256,3, activation='relu', padding='same')(conv3)\n",
    "drop3 = Dropout(0.5)(conv3)\n",
    "\n",
    "upconv4 = Conv2D(128,2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop3))\n",
    "concat4 = concatenate([upconv4,conv2],axis=3)\n",
    "conv4 = Conv2D(128,3, activation='relu', padding='same')(concat4)\n",
    "conv4 = Conv2D(128,3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "upconv5 = Conv2D(64,2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv4))\n",
    "concat5 = concatenate([upconv5,conv1],axis=3)\n",
    "conv5 = Conv2D(64,3, activation='relu', padding='same')(concat5)\n",
    "conv5 = Conv2D(64,3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "conv6 = Conv2D(amountOfClasses, (1,1), activation='softmax', padding='valid')(conv5)\n",
    "\n",
    "\n",
    "UNetModel = Model(inputs = model_inputs, outputs = conv6)\n",
    "UNetModel.compile(optimizer='adagrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']);\n",
    "print(UNetModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 1600, 1600, 20)    840       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1600, 1600, 9)     189       \n",
      "=================================================================\n",
      "Total params: 1,029\n",
      "Trainable params: 1,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelBasicNN = Sequential([\n",
    "    Conv2D(20, (1,1), input_shape=(imageSize[0], imageSize[1], inputChannels), activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])\n",
    "modelBasicNN.summary()\n",
    "\n",
    "weights = np.array([1,1,1,1,1,1,1,1,1])*3\n",
    "loss = weighted_categorical_crossentropy(weights)\n",
    "#\"categorical_crossentropy\"\n",
    "opt = keras.optimizers.SGD(lr=0.01)\n",
    "modelBasicNN.compile(loss = loss, optimizer = opt,  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training data and labels\n",
    "trainData,trainLabels = readSet(trainPaths)\n",
    "validationData,validationLabels = readSet(validationPaths)\n",
    "\n",
    "#trainWeights = getSampleWeights(trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples, validate on 1 samples\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 47s 16s/step - loss: 16.1822 - acc: 0.7528 - val_loss: 9.1205 - val_acc: 0.9135\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 48s 16s/step - loss: 16.0633 - acc: 0.7528 - val_loss: 9.1109 - val_acc: 0.9125\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "modelBasicNN.fit(trainData, trainLabels,validation_data=(validationData,validationLabels), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "UNetModel.save('networkModels/UNetModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170531.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170622.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170531_cropped.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170622_cropped.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170802.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170510.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170622.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170510_cropped.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170622_cropped.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170613.mat\n"
     ]
    }
   ],
   "source": [
    "# Use trained model to predict\n",
    "predictAndSaveSet(testPaths, modelBasicNN,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast_7:0\", shape=(1600, 1600), dtype=float32)\n",
      "(1600, 1600, 9)\n",
      "(1600, 1600, 9)\n",
      "Tensor(\"Neg_13:0\", shape=(1600, 1600), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GraphDef cannot be larger than 2GB.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-aef2448910a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mlosss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \"\"\"\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4083\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4084\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4085\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                 run_metadata):\n\u001b[1;32m   1296\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m         graph_def, self._current_version = self._graph._as_graph_def(\n\u001b[1;32m   1352\u001b[0m             \u001b[0mfrom_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m             add_shapes=self._add_shapes)\n\u001b[0m\u001b[1;32m   1354\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   2444\u001b[0m           \u001b[0mbytesize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GraphDef cannot be larger than 2GB.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GraphDef cannot be larger than 2GB."
     ]
    }
   ],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.metrics import categorical_accuracy\n",
    "import  tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "a=np.zeros((1600,1600))\n",
    "a1=createOneHot(a,amountOfClasses)\n",
    "b1=trainLabels[0,:,:,:];\n",
    "print(categorical_accuracy(a1,b1))\n",
    "a = tf.convert_to_tensor(a1, dtype=tf.float32)\n",
    "b = tf.convert_to_tensor(b1, dtype=tf.float32)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "losss = categorical_crossentropy(a,b)\n",
    "print(losss)\n",
    "#print(losss.eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30517578125\n"
     ]
    }
   ],
   "source": [
    "Sum = losss.eval(session=sess);\n",
    "print(sum(sum(Sum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2248752\n"
     ]
    }
   ],
   "source": [
    "count=0;\n",
    "for i in range(0,1600):\n",
    "    for j in range(0,1600):\n",
    "        if np.argmax(b1[i,j,:]) == 8: count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560000.0\n"
     ]
    }
   ],
   "source": [
    "z = categorical_accuracy(a,b)\n",
    "print(sum(sum(z.eval(session=sess))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(b1[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                   Type          Data/Info\n",
      "--------------------------------------------------\n",
      "Conv2D                     type          <class 'keras.layers.convolutional.Conv2D'>\n",
      "Conv2DTranspose            type          <class 'keras.layers.conv<...>utional.Conv2DTranspose'>\n",
      "Image                      module        <module 'PIL.Image' from <...>e-packages/PIL/Image.py'>\n",
      "MaxPooling2D               type          <class 'keras.layers.pooling.MaxPooling2D'>\n",
      "Sequential                 type          <class 'keras.models.Sequential'>\n",
      "Sum                        ndarray       1600x1600: 2560000 elems, type `float32`, 10240000 bytes (9.765625 Mb)\n",
      "a                          Tensor        Tensor(\"Const_42:0\", shap<...> 1600, 9), dtype=float32)\n",
      "a1                         ndarray       1600x1600x9: 23040000 elems, type `float64`, 184320000 bytes (175.78125 Mb)\n",
      "amountOfClasses            int           9\n",
      "b                          Tensor        Tensor(\"Const_43:0\", shap<...> 1600, 9), dtype=float32)\n",
      "b1                         ndarray       1600x1600x9: 23040000 elems, type `uint8`, 23040000 bytes (21.97265625 Mb)\n",
      "basePath                   str           /Volumes/mac_jannic_2017/<...>/Datasets/xFcnClassifier/\n",
      "categorical_accuracy       function      <function categorical_accuracy at 0x11f8ef1e0>\n",
      "categorical_crossentropy   function      <function categorical_cro<...>ssentropy at 0x11f8f1bf8>\n",
      "count                      int           2560000\n",
      "createOneHot               function      <function createOneHot at 0x10e77cd90>\n",
      "getTestPaths               function      <function getTestPaths at 0x121dc3598>\n",
      "getTrainPaths              function      <function getTrainPaths at 0x121dc3510>\n",
      "i                          int           1599\n",
      "imageSize                  list          n=2\n",
      "inputChannels              int           41\n",
      "j                          int           1599\n",
      "keras                      module        <module 'keras' from '/Us<...>kages/keras/__init__.py'>\n",
      "loadOneLabel               function      <function loadOneLabel at 0x121db6598>\n",
      "loadOneOrthomosaic         function      <function loadOneOrthomosaic at 0x120a20048>\n",
      "losss                      Tensor        Tensor(\"Neg_12:0\", shape=<...>00, 1600), dtype=float32)\n",
      "modelBasicNN               Sequential    <keras.models.Sequential object at 0x15a6d9d30>\n",
      "np                         module        <module 'numpy' from '/Us<...>kages/numpy/__init__.py'>\n",
      "numberOfEpochs             int           20\n",
      "oneHotToBinary             function      <function oneHotToBinary at 0x121dc32f0>\n",
      "opt                        SGD           <keras.optimizers.SGD object at 0x15a4706a0>\n",
      "plotImage                  function      <function plotImage at 0x121dc3488>\n",
      "plt                        module        <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "predictAndSaveOneImage     function      <function predictAndSaveOneImage at 0x121dc3378>\n",
      "predictAndSaveSet          function      <function predictAndSaveSet at 0x121dc3400>\n",
      "readSet                    function      <function readSet at 0x121db6840>\n",
      "sess                       Session       <tensorflow.python.client<...>on object at 0x11e4be978>\n",
      "sio                        module        <module 'scipy.io' from '<...>es/scipy/io/__init__.py'>\n",
      "testPaths                  list          n=10\n",
      "testSets                   list          n=2\n",
      "tf                         module        <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
      "trainData                  ndarray       3x1600x1600x41: 314880000 elems, type `uint8`, 314880000 bytes (300.29296875 Mb)\n",
      "trainLabels                ndarray       3x1600x1600x9: 69120000 elems, type `uint8`, 69120000 bytes (65.91796875 Mb)\n",
      "trainPaths                 list          n=3\n",
      "trainSets                  list          n=2\n",
      "validationData             ndarray       1x1600x1600x41: 104960000 elems, type `uint8`, 104960000 bytes (100.09765625 Mb)\n",
      "validationLabels           ndarray       1x1600x1600x9: 23040000 elems, type `uint8`, 23040000 bytes (21.97265625 Mb)\n",
      "validationPaths            list          n=1\n",
      "validationSets             list          n=2\n",
      "z                          Tensor        Tensor(\"Cast_3:0\", shape=<...>00, 1600), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170622.mat'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPaths[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
