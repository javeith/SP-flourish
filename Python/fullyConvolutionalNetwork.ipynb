{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Â Turn inFile into a one hot label\n",
    "def createOneHot(inFile,numberOfClasses):\n",
    "    outFile = np.zeros((inFile.shape[0],inFile.shape[1], numberOfClasses));\n",
    "    for i in range(0,inFile.shape[0]):\n",
    "        for j in range(0,inFile.shape[1]):\n",
    "            outFile[i,j,inFile[i,j]] = 1;\n",
    "    return outFile;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn 41 orthomosaics into one array. \n",
    "def loadOneOrthomosaic(imagePath1,imagePath2):\n",
    "    temp= imageio.imread(imagePath1 + '1.png');\n",
    "    inputData = np.zeros( (temp.shape[0],temp.shape[1],inputChannels) )\n",
    "    for i in range(1,25):\n",
    "        temp= imageio.imread(imagePath1 + str(i) + '.png');\n",
    "        inputData[:,:,i] = temp[:,:,0];\n",
    "    for i in range(1,16):\n",
    "        temp= imageio.imread(imagePath2 + str(i) + '.png');\n",
    "        inputData[:,:,i+25] = temp[:,:,0];\n",
    "    return np.expand_dims(inputData,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadOneOrthomosaic(imagePath):\n",
    "    temp= imageio.imread(imagePath1 + '1.png');\n",
    "    inputData = np.zeros(( temp.shape[0], temp.shape[1], inputChannels))\n",
    "    for i in range(1,41):\n",
    "        temp= imageio.imread(imagePath1 + str(i) + '.png');\n",
    "        inputData[:,:,i] = temp[:,:];\n",
    "    return np.expand_dims( inputData, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadOneLabel(imagePath):\n",
    "    temp = sio.loadmat(imagePath);\n",
    "    trainOneHotLabels =  createOneHot( temp['labeledPicture'], 9);\n",
    "    return np.expand_dims( trainOneHotLabels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readSet(paths):\n",
    "    numberOfImages = len(paths);\n",
    "    data = np.zeros( (numberOfImages,imageSize[1],imageSize[0],inputChannels) );\n",
    "    labels = np.zeros((numberOfImages,imageSize[1],imageSize[0],amountOfClasses))\n",
    "    for i in range(0,numberOfImages):\n",
    "        data[i,:,:,:] = loadOneOrthomosaic(paths[i][0]);\n",
    "        labels[i,:,:,:] = loadOneLabel(paths[i][1]);\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def makeDimensionsEven(inArray):\n",
    "    if inArray.shape[0] % 2 != 0:\n",
    "        middleArray = np.append(inArray, np.zeros((1,inArray.shape[1])), axis=0)\n",
    "    else:\n",
    "        middleArray = inArray\n",
    "    if middleArray.shape[1] % 2 != 0:\n",
    "        outArray = np.append(middleArray, np.zeros((middleArray.shape[0],1)), axis=1)\n",
    "    else:\n",
    "        outArray = middleArray;\n",
    "    return outArray;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def loadData(pathArray):\n",
    "    # each row of pathArray belongs to one dataset and has pathNIR, pathVIS, pathLabel\n",
    "    #trainDataIn = np.load('trainingData.npy');\n",
    "    outData = [];\n",
    "    temp = returnOrthomosaicArray(pathArray[0,0],pathArray[0,1]);\n",
    "    outData.append(temp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, 5, input_shape=inputDataShape, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, 5, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2DTranspose(128, 6, strides=2, padding='valid', activation='relu'),\n",
    "    Conv2DTranspose(64, 6, strides=2, activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basePath = '/Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/';\n",
    "\n",
    "imagePath1 = basePath + 'Data/FIP/20170622/Band';\n",
    "labelpath1 = basePath + 'Labels/FIP20170622.mat';\n",
    "\n",
    "imagePath2 = basePath + 'Data/Ximea_Tamron/20170510/Band';\n",
    "labelpath2 = basePath + 'Labels/XimeaT20170510.mat';\n",
    "\n",
    "imagePath3 = basePath + 'Data/Ximea_Tamron/20170622/Band';\n",
    "labelpath3 = basePath + 'Labels/XimeaT20170622.mat';\n",
    "\n",
    "trainPaths = [[imagePath1,labelpath1],[imagePath2,labelpath2],[imagePath3,labelpath3]];\n",
    "\n",
    "amountOfClasses = 9;\n",
    "inputChannels = 41;\n",
    "imageSize = [1600,1600]; # [X,Y]\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(20, 5, input_shape=(None, None, inputChannels), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2DTranspose(20, 6, strides=2, activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training data and labels\n",
    "\n",
    "trainData,trainLabels = readSet(trainPaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conv2D',\n",
       " 'Conv2DTranspose',\n",
       " 'Image',\n",
       " 'In',\n",
       " 'MaxPooling2D',\n",
       " 'Out',\n",
       " 'Sequential',\n",
       " '_',\n",
       " '__',\n",
       " '___',\n",
       " '__builtin__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_dh',\n",
       " '_i',\n",
       " '_i1',\n",
       " '_i10',\n",
       " '_i11',\n",
       " '_i2',\n",
       " '_i3',\n",
       " '_i4',\n",
       " '_i5',\n",
       " '_i6',\n",
       " '_i7',\n",
       " '_i8',\n",
       " '_i9',\n",
       " '_ih',\n",
       " '_ii',\n",
       " '_iii',\n",
       " '_oh',\n",
       " '_sh',\n",
       " 'amountOfClasses',\n",
       " 'basePath',\n",
       " 'createOneHot',\n",
       " 'exit',\n",
       " 'get_ipython',\n",
       " 'imagePath1',\n",
       " 'imagePath2',\n",
       " 'imagePath3',\n",
       " 'imageSize',\n",
       " 'imageio',\n",
       " 'inputChannels',\n",
       " 'keras',\n",
       " 'labelpath1',\n",
       " 'labelpath2',\n",
       " 'labelpath3',\n",
       " 'loadOneLabel',\n",
       " 'loadOneOrthomosaic',\n",
       " 'model',\n",
       " 'np',\n",
       " 'plt',\n",
       " 'quit',\n",
       " 'readSet',\n",
       " 'sio',\n",
       " 'trainData',\n",
       " 'trainLabels',\n",
       " 'trainPaths']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, None, None, 20)    20520     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, None, None, 20)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, None, None, 20)    14420     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 9)     189       \n",
      "=================================================================\n",
      "Total params: 35,129\n",
      "Trainable params: 35,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3/3 [==============================] - 225s 75s/step - loss: 3.3614 - acc: 0.7761\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=2);\n",
    "\n",
    "model.fit(trainData, trainLabels, epochs=1,callbacks=[early_stopping]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('networkModels/FCN-None-None-conv5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
