{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "# Turn inFile into a one hot label\n",
    "def createOneHot(inFile,amountOfClasses):\n",
    "    outFile = np.zeros((inFile.shape[0],inFile.shape[1], amountOfClasses));\n",
    "    for i in range(0,inFile.shape[0]):\n",
    "        for j in range(0,inFile.shape[1]):\n",
    "            #if inFile[i,j] != 0:\n",
    "            outFile[i,j,int(inFile[i,j]-1)] = 1;\n",
    "    return outFile;\n",
    "\n",
    "# Turn 41 orthomosaics into one array. From 2 separate paths, 1-25 and 1-16\n",
    "def loadOneOrthomosaic(imagePath1,imagePath2):\n",
    "    temp= imageio.imread(imagePath1 + '1.png');\n",
    "    inputData = np.zeros( (temp.shape[0],temp.shape[1],inputChannels) ,dtype=np.dtype('uint8'))\n",
    "    for i in range(1,25):\n",
    "        temp= imageio.imread(imagePath1 + str(i) + '.png');\n",
    "        inputData[:,:,i] = temp[:,:,0];\n",
    "    for i in range(1,16):\n",
    "        temp= imageio.imread(imagePath2 + str(i) + '.png');\n",
    "        inputData[:,:,i+25] = temp[:,:,0];\n",
    "    return np.expand_dims(inputData,axis=0)\n",
    "\n",
    "# Turn 41 orthomosaics into one array. From 1 path with Bands 1 to 41\n",
    "def loadOneOrthomosaic(imagePath):\n",
    "    temp= imageio.imread(imagePath + '1.png');\n",
    "    inputData = np.zeros(( temp.shape[0], temp.shape[1], inputChannels),dtype=np.dtype('uint8'))\n",
    "    for i in range(1,41):\n",
    "        temp= imageio.imread(imagePath + str(i) + '.png');\n",
    "        inputData[:,:,i] = temp[:,:];\n",
    "    return np.expand_dims( inputData, axis=0)\n",
    "\n",
    "# Load one label from a .mat\n",
    "def loadOneLabel(imagePath):\n",
    "    temp = sio.loadmat(imagePath);\n",
    "    trainOneHotLabels =  createOneHot( temp['labeledPicture'], amountOfClasses);\n",
    "    return np.expand_dims( trainOneHotLabels, axis=0)\n",
    "\n",
    "# Read training data and labels for an array of path tuples, returns (data,labels)\n",
    "def readSet(paths):\n",
    "    numberOfImages = len(paths);\n",
    "    data = np.zeros( (numberOfImages,imageSize[1],imageSize[0],inputChannels), dtype=np.dtype('uint8'));\n",
    "    labels = np.zeros((numberOfImages,imageSize[1],imageSize[0],amountOfClasses), dtype=np.dtype('uint8'))\n",
    "    for i in range(0,numberOfImages):\n",
    "        data[i,:,:,:] = loadOneOrthomosaic(paths[i][0]);\n",
    "        labels[i,:,:,:] = loadOneLabel(paths[i][1]);\n",
    "    return data,labels\n",
    "\n",
    "def oneHotToCategorical(oneHotLabel):\n",
    "    temp = np.zeros((oneHotLabel.shape[1],oneHotLabel.shape[2]), dtype=np.dtype('uint8') );\n",
    "    for i in range(0,oneHotLabel.shape[1]):\n",
    "        for j in range(0,oneHotLabel.shape[2]):\n",
    "            #temp[i,j] = np.argmax(oneHotLabel[0,i,j,:]) + 1;\n",
    "            temp[i,j] = np.argmax(oneHotLabel[0,i,j,:]);\n",
    "    return temp\n",
    "\n",
    "def predictAndSaveOneImage(inPath,outPath,FCNmodel):\n",
    "    testImage = loadOneOrthomosaic(inPath);\n",
    "    testLabelPredict = FCNmodel.predict(testImage);\n",
    "    testLabelPredictCat = oneHotToCategorical(testLabelPredict);\n",
    "    sio.savemat(outPath, mdict={'testLabelPredict': testLabelPredictCat});\n",
    "\n",
    "def predictAndSaveSet(pathArray, FCNmodel):\n",
    "    numberOfImages = len(pathArray);\n",
    "    for i in range(0,numberOfImages):\n",
    "        predictAndSaveOneImage(pathArray[i][0], pathArray[i][1], FCNmodel)\n",
    "        print('Saved ' + pathArray[i][1])\n",
    "        \n",
    "def plotImage(image):\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data paths\n",
    "basePath = '/Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/';\n",
    "\n",
    "imagePath1 = basePath + 'Data/FIP/20170622/Band';\n",
    "labelpath1 = basePath + 'Labels/FIP20170622.mat';\n",
    "imagePath2 = basePath + 'Data/Ximea_Tamron/20170510/Band';\n",
    "labelpath2 = basePath + 'Labels/XimeaT20170510.mat';\n",
    "imagePath3 = basePath + 'Data/Ximea_Tamron/20170622/Band';\n",
    "labelpath3 = basePath + 'Labels/XimeaT20170622.mat';\n",
    "\n",
    "trainPaths = [[imagePath1,labelpath1],[imagePath2,labelpath2],[imagePath3,labelpath3]];\n",
    "del imagePath1,labelpath1,imagePath2,labelpath2,imagePath3,labelpath3\n",
    "\n",
    "inPath1 = basePath + 'testData/Ximea_Tamron/20170613/Band';\n",
    "outpath1 = basePath + 'testLabelPredict/XimeaT_20170613.mat';\n",
    "inPath2 = basePath + 'testData/FIP/20170531/Band';\n",
    "outpath2 = basePath + 'testLabelPredict/FIP_20170531.mat';\n",
    "inPath3 = basePath + 'testData/FIP/20170622/Band';\n",
    "outpath3 = basePath + 'testLabelPredict/FIP_20170622.mat';\n",
    "inPath4 = basePath + 'testData/FIP/20170802/Band';\n",
    "outpath4 = basePath + 'testLabelPredict/FIP_20170802.mat';\n",
    "inPath5 = trainPaths[0][0];\n",
    "outpath5 = basePath + 'testLabelPredict/FIP_20170622TRAIN.mat';\n",
    "inPath6 = trainPaths[1][0];\n",
    "outpath6 = basePath + 'testLabelPredict/XimeaT_20170510TRAIN.mat';\n",
    "inPath7 = trainPaths[2][0];\n",
    "outpath7 = basePath + 'testLabelPredict/XimeaT_20170622TRAIN.mat';\n",
    "\n",
    "testTrainPaths = [[inPath5,outpath5],[inPath6,outpath6],[inPath7,outpath7]];\n",
    "testPaths = [[inPath1,outpath1],[inPath2,outpath2],[inPath3,outpath3],[inPath4,outpath4]];\n",
    "del inPath1,outpath1,inPath2,outpath2,inPath3,outpath3,inPath4,outpath4,inPath5,outpath5,inPath6,outpath6,inPath7,outpath7,basePath\n",
    "\n",
    "# Data parameters\n",
    "amountOfClasses = 9;\n",
    "inputChannels = 41;\n",
    "imageSize = [1600,1600]; # [X,Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 1600, 1600, 20)    840       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1600, 1600, 9)     189       \n",
      "=================================================================\n",
      "Total params: 1,029\n",
      "Trainable params: 1,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelBasicNN = Sequential([\n",
    "    Conv2D(20, (1,1), input_shape=(imageSize[0], imageSize[1], inputChannels), activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])\n",
    "modelBasicNN.summary()\n",
    "modelBasicNN.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1596, 1596, 20)    20520     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 798, 798, 20)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 1600, 1600, 20)    14420     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1600, 1600, 8)     168       \n",
      "=================================================================\n",
      "Total params: 35,108\n",
      "Trainable params: 35,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(20, 5, input_shape=(imageSize[0], imageSize[1], inputChannels), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2DTranspose(20, 6, strides=2, activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           (None, 1600, 1600, 4 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 1600, 1600, 6 23680       input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 1600, 1600, 6 36928       conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling2D) (None, 800, 800, 64) 0           conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 800, 800, 128 73856       max_pooling2d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 800, 800, 128 147584      conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling2D) (None, 400, 400, 128 0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 400, 400, 256 295168      max_pooling2d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 400, 400, 256 590080      conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling2D) (None, 800, 800, 256 0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 800, 800, 128 131200      up_sampling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 800, 800, 256 0           conv2d_152[0][0]                 \n",
      "                                                                 conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 800, 800, 128 295040      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 800, 800, 128 147584      conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling2D) (None, 1600, 1600, 1 0           conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 1600, 1600, 6 32832       up_sampling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1600, 1600, 1 0           conv2d_155[0][0]                 \n",
      "                                                                 conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 1600, 1600, 6 73792       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 1600, 1600, 6 36928       conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 1600, 1600, 9 585         conv2d_157[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,885,257\n",
      "Trainable params: 1,885,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Cropping2D, UpSampling2D,concatenate\n",
    "\n",
    "#crop1 = Cropping2D(cropping=((0, 0), (0, 0)))(conv1) # cropping=((Top, Bottom), (Left, Right))\n",
    "\n",
    "model_inputs = Input(shape=(imageSize[0], imageSize[1], inputChannels))\n",
    "\n",
    "conv1 = Conv2D(64,3, activation='relu', padding='same')(model_inputs)\n",
    "conv1 = Conv2D(64,3, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')(conv1)\n",
    "\n",
    "conv2 = Conv2D(128,3, activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(128,3, activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')(conv2)\n",
    "\n",
    "conv3 = Conv2D(256,3, activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(256,3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "upconv4 = Conv2D(128,2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv3))\n",
    "concat4 = concatenate([upconv4,conv2],axis=3)\n",
    "conv4 = Conv2D(128,3, activation='relu', padding='same')(concat4)\n",
    "conv4 = Conv2D(128,3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "upconv5 = Conv2D(64,2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv4))\n",
    "concat5 = concatenate([upconv5,conv1],axis=3)\n",
    "conv5 = Conv2D(64,3, activation='relu', padding='same')(concat5)\n",
    "conv5 = Conv2D(64,3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "conv6 = Conv2D(amountOfClasses, (1,1), activation='softmax', padding='valid')(conv5)\n",
    "\n",
    "\n",
    "UNetModel = Model(inputs = model_inputs, outputs = conv6)\n",
    "UNetModel.compile(optimizer='adagrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']);\n",
    "print(UNetModel.summary())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model2Conv = Sequential([\n",
    "    Conv2D(128, 3, input_shape=(imageSize[0], imageSize[1], inputChannels), activation='relu'),\n",
    "    Conv2D(128, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2DTranspose(20, 6, strides=2, activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])\n",
    "model2Conv.summary()\n",
    "model2Conv.compile(optimizer='adagrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, 5, input_shape=inputDataShape, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, 5, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2DTranspose(128, 6, strides=2, padding='valid', activation='relu'),\n",
    "    Conv2DTranspose(64, 6, strides=2, activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training data and labels\n",
    "trainData,trainLabels = readSet(trainPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 38s 13s/step - loss: 2.8838 - acc: 0.1562\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 31s 10s/step - loss: 3.9083 - acc: 0.7788\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 32s 11s/step - loss: 2.8042 - acc: 0.9277\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "modelBasicNN.fit(trainData, trainLabels, epochs=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model2Conv.save('networkModels/FCN-1600-1600-128conv3-128conv3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/XimeaT_20170613.mat\n",
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170531.mat\n",
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170622.mat\n",
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170802.mat\n",
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP20170622.mat\n",
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/XimeaT20170510.mat\n",
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/XimeaT20170622.mat\n"
     ]
    }
   ],
   "source": [
    "# Use trained model to predict\n",
    "predictAndSaveSet(testTrainPaths, modelBasicNN);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Network plotting stuff. not working yet\n",
    "import pydot_ng as pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "plot_model(modelBasicNN, to_file='model2Conv.png')\n",
    "\n",
    "import pydot_ng as pydot\n",
    "import graphviz\n",
    "print(pydot.find_graphviz())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
