{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "# Turn inFile into a one hot label\n",
    "def createOneHot(inFile,amountOfClasses):\n",
    "    outFile = np.zeros((inFile.shape[0],inFile.shape[1], amountOfClasses));\n",
    "    for i in range(0,inFile.shape[0]):\n",
    "        for j in range(0,inFile.shape[1]):\n",
    "            #if inFile[i,j] != 0:\n",
    "            outFile[i,j,int(inFile[i,j]-1)] = 1;\n",
    "    return outFile;\n",
    "\n",
    "# Turn 41 orthomosaics into one array. From 2 separate paths, 1-25 and 1-16\n",
    "def loadOneOrthomosaic(imagePath1,imagePath2):\n",
    "    temp= imageio.imread(imagePath1 + '1.png');\n",
    "    inputData = np.zeros( (temp.shape[0],temp.shape[1],inputChannels) ,dtype=np.dtype('uint8'))\n",
    "    for i in range(1,25):\n",
    "        temp= imageio.imread(imagePath1 + 'Band' + str(i) + '.png');\n",
    "        inputData[:,:,i] = temp[:,:,0];\n",
    "    for i in range(1,16):\n",
    "        temp= imageio.imread(imagePath2 + 'Band' + str(i) + '.png');\n",
    "        inputData[:,:,i+25] = temp[:,:,0];\n",
    "    return np.expand_dims(inputData,axis=0)\n",
    "\n",
    "# Turn 41 orthomosaics into one array. From 1 path with Bands 1 to 41\n",
    "def loadOneOrthomosaic(imagePath):\n",
    "    temp= imageio.imread(imagePath + 'Band1.png');\n",
    "    inputData = np.zeros(( temp.shape[0], temp.shape[1], inputChannels),dtype=np.dtype('uint8'))\n",
    "    for i in range(1,41):\n",
    "        temp= imageio.imread(imagePath + 'Band' + str(i) + '.png');\n",
    "        inputData[:,:,i] = temp[:,:];\n",
    "    return np.expand_dims( inputData, axis=0)\n",
    "\n",
    "# Load one label from a .mat\n",
    "def loadOneLabel(imagePath):\n",
    "    temp = sio.loadmat(imagePath);\n",
    "    trainOneHotLabels =  createOneHot( temp['labeledPicture'], amountOfClasses);\n",
    "    return np.expand_dims( trainOneHotLabels, axis=0)\n",
    "\n",
    "# Read training data and labels for an array of path tuples, returns (data,labels)\n",
    "def readSet(paths):\n",
    "    numberOfImages = len(paths);\n",
    "    data = np.zeros( (numberOfImages,imageSize[1],imageSize[0],inputChannels), dtype=np.dtype('uint8'));\n",
    "    labels = np.zeros((numberOfImages,imageSize[1],imageSize[0],amountOfClasses), dtype=np.dtype('uint8'))\n",
    "    for i in range(0,numberOfImages):\n",
    "        data[i,:,:,:] = loadOneOrthomosaic(paths[i][0]);\n",
    "        labels[i,:,:,:] = loadOneLabel(paths[i][1]);\n",
    "    return data,labels\n",
    "\n",
    "def oneHotToCategorical(oneHotLabel,threshold):\n",
    "    temp = np.zeros((oneHotLabel.shape[1],oneHotLabel.shape[2]), dtype=np.dtype('uint8') );\n",
    "    for i in range(0,oneHotLabel.shape[1]):\n",
    "        for j in range(0,oneHotLabel.shape[2]):\n",
    "            #temp[i,j] = np.argmax(oneHotLabel[0,i,j,:]) + 1;\n",
    "            if np.argmax(oneHotLabel[0,i,j,:])>threshold:\n",
    "                temp[i,j] = np.argmax(oneHotLabel[0,i,j,:])\n",
    "    return temp\n",
    "\n",
    "def predictAndSaveOneImage(inPath,outPath,FCNmodel,threshold):\n",
    "    testImage = loadOneOrthomosaic(inPath);\n",
    "    testLabelPredict = FCNmodel.predict(testImage);\n",
    "    testLabelPredictCat = oneHotToCategorical(testLabelPredict,threshold);\n",
    "    sio.savemat(outPath, mdict={'testLabelPredict': testLabelPredictCat});\n",
    "\n",
    "def predictAndSaveSet(pathArray, FCNmodel,threshold):\n",
    "    numberOfImages = len(pathArray);\n",
    "    for i in range(0,numberOfImages):\n",
    "        predictAndSaveOneImage(pathArray[i][0], pathArray[i][1], FCNmodel,threshold)\n",
    "        print('Saved ' + pathArray[i][1])\n",
    "        \n",
    "def plotImage(image):\n",
    "    plt.imshow(image)\n",
    "    \n",
    "def getTrainPaths(paths):\n",
    "    folders = ['FIP','Ximea_Tamron']\n",
    "    fullPath = []\n",
    "    for imageType in paths:\n",
    "        for date in imageType:\n",
    "            temp = []\n",
    "            temp.append(basePath+'trainData/'+folders[paths.index(imageType)]+'/'+date+'/')\n",
    "            temp.append(basePath+'trainLabels/'+folders[paths.index(imageType)]+'_'+date+'.mat') \n",
    "            fullPath.append(temp)\n",
    "    return fullPath\n",
    "    \n",
    "def getTestPaths(paths):\n",
    "    folders = ['FIP','Ximea_Tamron']\n",
    "    fullPath = []\n",
    "    for imageType in paths:\n",
    "        for date in imageType:\n",
    "            temp = []\n",
    "            temp.append(basePath+'testData/'+folders[paths.index(imageType)]+'/'+date+'/')\n",
    "            temp.append(basePath+'testLabelPredict/'+folders[paths.index(imageType)]+'_'+date+'.mat') \n",
    "            fullPath.append(temp)\n",
    "    return fullPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data paths\n",
    "basePath = '/Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/';\n",
    "\n",
    "trainSets = [\n",
    "    #FIP\n",
    "    [\n",
    "        '20170622'\n",
    "    ],\n",
    "    #Ximea_Tamron\n",
    "    [\n",
    "        '20170510',\n",
    "        '20170622'\n",
    "    ]\n",
    "]\n",
    "\n",
    "validationSets = [\n",
    "    #FIP\n",
    "    [\n",
    "        '20170531'\n",
    "    ],\n",
    "    #Ximea_Tamron\n",
    "    [\n",
    "    ]\n",
    "]\n",
    "\n",
    "testSets = [\n",
    "    #FIP\n",
    "    [\n",
    "        '20170531', \n",
    "        '20170622',\n",
    "        '20170531_cropped',\n",
    "        '20170622_cropped',\n",
    "        '20170802'\n",
    "    ],\n",
    "    #Ximea_Tamron\n",
    "    [\n",
    "        '20170510',\n",
    "        '20170622',\n",
    "        '20170510_cropped',\n",
    "        '20170622_cropped',\n",
    "        '20170613'\n",
    "    ]\n",
    "]\n",
    "    \n",
    "trainPaths = getTrainPaths(trainSets)\n",
    "validationPaths = getTrainPaths(validationSets)\n",
    "testPaths = getTestPaths(testSets)\n",
    "\n",
    "# Data parameters\n",
    "amountOfClasses = 9;\n",
    "inputChannels = 41;\n",
    "imageSize = [1600,1600]; # [X,Y]\n",
    "\n",
    "numberOfEpochs = 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1600, 1600, 4 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1600, 1600, 6 23680       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1600, 1600, 6 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 800, 800, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 800, 800, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 800, 800, 128 147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 400, 400, 128 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 400, 400, 256 295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 400, 400, 256 590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400, 400, 256 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 800, 800, 256 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 800, 800, 128 131200      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800, 800, 256 0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 800, 800, 128 295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 800, 800, 128 147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 1600, 1600, 1 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1600, 1600, 6 32832       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1600, 1600, 1 0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 1600, 1600, 6 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1600, 1600, 6 36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1600, 1600, 9 585         conv2d_12[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,885,257\n",
      "Trainable params: 1,885,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Cropping2D, UpSampling2D,concatenate,Dropout\n",
    "\n",
    "#crop1 = Cropping2D(cropping=((0, 0), (0, 0)))(conv1) # cropping=((Top, Bottom), (Left, Right))\n",
    "\n",
    "model_inputs = Input(shape=(imageSize[0], imageSize[1], inputChannels))\n",
    "\n",
    "conv1 = Conv2D(64,3, activation='relu', padding='same')(model_inputs)\n",
    "conv1 = Conv2D(64,3, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')(conv1)\n",
    "\n",
    "conv2 = Conv2D(128,3, activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(128,3, activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')(conv2)\n",
    "\n",
    "conv3 = Conv2D(256,3, activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(256,3, activation='relu', padding='same')(conv3)\n",
    "drop3 = Dropout(0.5)(conv3)\n",
    "\n",
    "upconv4 = Conv2D(128,2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop3))\n",
    "concat4 = concatenate([upconv4,conv2],axis=3)\n",
    "conv4 = Conv2D(128,3, activation='relu', padding='same')(concat4)\n",
    "conv4 = Conv2D(128,3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "upconv5 = Conv2D(64,2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv4))\n",
    "concat5 = concatenate([upconv5,conv1],axis=3)\n",
    "conv5 = Conv2D(64,3, activation='relu', padding='same')(concat5)\n",
    "conv5 = Conv2D(64,3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "conv6 = Conv2D(amountOfClasses, (1,1), activation='softmax', padding='valid')(conv5)\n",
    "\n",
    "\n",
    "UNetModel = Model(inputs = model_inputs, outputs = conv6)\n",
    "UNetModel.compile(optimizer='adagrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']);\n",
    "print(UNetModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 1600, 1600, 20)    840       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1600, 1600, 9)     189       \n",
      "=================================================================\n",
      "Total params: 1,029\n",
      "Trainable params: 1,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelBasicNN = Sequential([\n",
    "    Conv2D(20, (1,1), input_shape=(imageSize[0], imageSize[1], inputChannels), activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])\n",
    "modelBasicNN.summary()\n",
    "modelBasicNN.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training data and labels\n",
    "trainData,trainLabels = readSet(trainPaths)\n",
    "validationData,validationLabels = readSet(validationPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples, validate on 1 samples\n",
      "Epoch 1/4\n",
      "3/3 [==============================] - 40s 13s/step - loss: 5.4719 - acc: 0.0014 - val_loss: 3.6106 - val_acc: 0.8969\n",
      "Epoch 2/4\n",
      "3/3 [==============================] - 37s 12s/step - loss: 5.4393 - acc: 0.7658 - val_loss: 3.5952 - val_acc: 0.8969\n",
      "Epoch 3/4\n",
      "3/3 [==============================] - 31s 10s/step - loss: 5.4290 - acc: 0.7658 - val_loss: 3.5890 - val_acc: 0.8969\n",
      "Epoch 4/4\n",
      "3/3 [==============================] - 31s 10s/step - loss: 5.4235 - acc: 0.7658 - val_loss: 3.5516 - val_acc: 0.8969\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "modelBasicNN.fit(trainData, trainLabels,validation_data=(validationData,validationLabels), epochs=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "UNetModel.save('networkModels/UNetModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170531.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170622.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170531_cropped.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170622_cropped.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170802.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170510.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170622.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170510_cropped.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170622_cropped.mat\n",
      "Saved /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/Ximea_Tamron_20170613.mat\n"
     ]
    }
   ],
   "source": [
    "# Use trained model to predict\n",
    "predictAndSaveSet(testPaths, modelBasicNN,.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testImage = loadOneOrthomosaic('/Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testData/FIP/20170531/');\n",
    "testLabelPredict = modelBasicNN.predict(testImage);\n",
    "testLabelPredictCat = oneHotToCategorical(testLabelPredict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1104096 , 0.1104096 , 0.1104096 , 0.1104096 , 0.1104096 ,\n",
       "       0.1104096 , 0.1104096 , 0.1104096 , 0.11672311], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabelPredict[0,400,800,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
