{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "# Turn inFile into a one hot label\n",
    "def createOneHot(inFile,amountOfClasses):\n",
    "    outFile = np.zeros((inFile.shape[0],inFile.shape[1], amountOfClasses));\n",
    "    for i in range(0,inFile.shape[0]):\n",
    "        for j in range(0,inFile.shape[1]):\n",
    "            if inFile[i,j] != 0:\n",
    "                outFile[i,j,int(inFile[i,j]-1)] = 1;\n",
    "    return outFile;\n",
    "\n",
    "# Turn 41 orthomosaics into one array. From 2 separate paths, 1-25 and 1-16\n",
    "def loadOneOrthomosaic(imagePath1,imagePath2):\n",
    "    temp= imageio.imread(imagePath1 + '1.png');\n",
    "    inputData = np.zeros( (temp.shape[0],temp.shape[1],inputChannels) ,dtype=np.dtype('uint8'))\n",
    "    for i in range(1,25):\n",
    "        temp= imageio.imread(imagePath1 + str(i) + '.png');\n",
    "        inputData[:,:,i] = temp[:,:,0];\n",
    "    for i in range(1,16):\n",
    "        temp= imageio.imread(imagePath2 + str(i) + '.png');\n",
    "        inputData[:,:,i+25] = temp[:,:,0];\n",
    "    return np.expand_dims(inputData,axis=0)\n",
    "\n",
    "# Turn 41 orthomosaics into one array. From 1 path with Bands 1 to 41\n",
    "def loadOneOrthomosaic(imagePath):\n",
    "    temp= imageio.imread(imagePath + '1.png');\n",
    "    inputData = np.zeros(( temp.shape[0], temp.shape[1], inputChannels),dtype=np.dtype('uint8'))\n",
    "    for i in range(1,41):\n",
    "        temp= imageio.imread(imagePath + str(i) + '.png');\n",
    "        inputData[:,:,i] = temp[:,:];\n",
    "    return np.expand_dims( inputData, axis=0)\n",
    "\n",
    "# Load one label from a .mat\n",
    "def loadOneLabel(imagePath):\n",
    "    temp = sio.loadmat(imagePath);\n",
    "    trainOneHotLabels =  createOneHot( temp['labeledPicture'], amountOfClasses);\n",
    "    return np.expand_dims( trainOneHotLabels, axis=0)\n",
    "\n",
    "# Read training data and labels for an array of path tuples, returns (data,labels)\n",
    "def readSet(paths):\n",
    "    numberOfImages = len(paths);\n",
    "    data = np.zeros( (numberOfImages,imageSize[1],imageSize[0],inputChannels), dtype=np.dtype('uint8'));\n",
    "    labels = np.zeros((numberOfImages,imageSize[1],imageSize[0],amountOfClasses), dtype=np.dtype('uint8'))\n",
    "    for i in range(0,numberOfImages):\n",
    "        data[i,:,:,:] = loadOneOrthomosaic(paths[i][0]);\n",
    "        labels[i,:,:,:] = loadOneLabel(paths[i][1]);\n",
    "    return data,labels\n",
    "\n",
    "def oneHotToCategorical(oneHotLabel):\n",
    "    temp = np.zeros((oneHotLabel.shape[1],oneHotLabel.shape[2]), dtype=np.dtype('uint8') );\n",
    "    for i in range(0,oneHotLabel.shape[1]):\n",
    "        for j in range(0,oneHotLabel.shape[2]):\n",
    "            temp[i,j] = np.argmax(oneHotLabel[0,i,j,:]) + 1;\n",
    "    return temp\n",
    "\n",
    "def predictAndSaveOneImage(inPath,outPath,FCNmodel):\n",
    "    testImage = loadOneOrthomosaic(inPath);\n",
    "    testLabelPredict = FCNmodel.predict(testImage);\n",
    "    testLabelPredictCat = oneHotToCategorical(testLabelPredict);\n",
    "    sio.savemat(outPath, mdict={'testLabelPredict': testLabelPredictCat});\n",
    "\n",
    "def predictAndSaveSet(pathArray, FCNmodel):\n",
    "    numberOfImages = len(pathArray);\n",
    "    for i in range(0,numberOfImages):\n",
    "        predictAndSaveOneImage(pathArray[i][0], pathArray[i][1], FCNmodel)\n",
    "        print('Printed ' + pathArray[i][1])\n",
    "        \n",
    "def plotImage(image):\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basePath = '/Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/';\n",
    "\n",
    "imagePath1 = basePath + 'Data/FIP/20170622/Band';\n",
    "labelpath1 = basePath + 'Labels/FIP20170622.mat';\n",
    "imagePath2 = basePath + 'Data/Ximea_Tamron/20170510/Band';\n",
    "labelpath2 = basePath + 'Labels/XimeaT20170510.mat';\n",
    "imagePath3 = basePath + 'Data/Ximea_Tamron/20170622/Band';\n",
    "labelpath3 = basePath + 'Labels/XimeaT20170622.mat';\n",
    "\n",
    "trainPaths = [[imagePath1,labelpath1],[imagePath2,labelpath2],[imagePath3,labelpath3]];\n",
    "del imagePath1,labelpath1,imagePath2,labelpath2,imagePath3,labelpath3,basePath\n",
    "\n",
    "amountOfClasses = 8;\n",
    "inputChannels = 41;\n",
    "imageSize = [1600,1600]; # [X,Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1596, 1596, 20)    20520     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 798, 798, 20)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 1600, 1600, 20)    14420     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1600, 1600, 8)     168       \n",
      "=================================================================\n",
      "Total params: 35,108\n",
      "Trainable params: 35,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(20, 5, input_shape=(imageSize[0], imageSize[1], inputChannels), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2DTranspose(20, 6, strides=2, activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1596, 1596, 30)    30780     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1592, 1592, 15)    11265     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 796, 796, 15)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 1600, 1600, 20)    30020     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1600, 1600, 8)     168       \n",
      "=================================================================\n",
      "Total params: 72,233\n",
      "Trainable params: 72,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2Conv = Sequential([\n",
    "    Conv2D(30, 5, input_shape=(imageSize[0], imageSize[1], inputChannels), activation='relu'),\n",
    "    Conv2D(15, 5, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2DTranspose(15, 10, strides=2, activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])\n",
    "model2Conv.summary()\n",
    "model2Conv.compile(optimizer='adagrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, 5, input_shape=inputDataShape, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, 5, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2DTranspose(128, 6, strides=2, padding='valid', activation='relu'),\n",
    "    Conv2DTranspose(64, 6, strides=2, activation='relu'),\n",
    "    Conv2D(amountOfClasses, (1,1), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'whos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6a9ba071cdf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the training data and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainPaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwhos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'whos' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the training data and labels\n",
    "trainData,trainLabels = readSet(trainPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type          Data/Info\n",
      "------------------------------------------------\n",
      "Conv2D                   type          <class 'keras.layers.convolutional.Conv2D'>\n",
      "Conv2DTranspose          type          <class 'keras.layers.conv<...>utional.Conv2DTranspose'>\n",
      "Image                    module        <module 'PIL.Image' from <...>e-packages/PIL/Image.py'>\n",
      "MaxPooling2D             type          <class 'keras.layers.pooling.MaxPooling2D'>\n",
      "Sequential               type          <class 'keras.models.Sequential'>\n",
      "a                        AxesImage     AxesImage(112.68,36;217.44x217.44)\n",
      "amountOfClasses          int           8\n",
      "createOneHot             function      <function createOneHot at 0x119316e18>\n",
      "imageSize                list          n=2\n",
      "imageio                  module        <module 'imageio' from '/<...>ges/imageio/__init__.py'>\n",
      "inputChannels            int           41\n",
      "keras                    module        <module 'keras' from '/Us<...>kages/keras/__init__.py'>\n",
      "loadOneLabel             function      <function loadOneLabel at 0x11931df28>\n",
      "loadOneOrthomosaic       function      <function loadOneOrthomosaic at 0x119307048>\n",
      "model2Conv               Sequential    <keras.models.Sequential object at 0x11932d908>\n",
      "np                       module        <module 'numpy' from '/Us<...>kages/numpy/__init__.py'>\n",
      "oneHotToCategorical      function      <function oneHotToCategorical at 0x117efaa60>\n",
      "plt                      module        <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "predictAndSaveOneImage   function      <function predictAndSaveOneImage at 0x1193072f0>\n",
      "predictAndSaveSet        function      <function predictAndSaveSet at 0x119316d08>\n",
      "readSet                  function      <function readSet at 0x1057fef28>\n",
      "sio                      module        <module 'scipy.io' from '<...>es/scipy/io/__init__.py'>\n",
      "testImage                ndarray       2x2: 4 elems, type `float64`, 32 bytes\n",
      "trainData                ndarray       3x1600x1600x41: 314880000 elems, type `uint8`, 314880000 bytes (300.29296875 Mb)\n",
      "trainLabels              ndarray       3x1600x1600x8: 61440000 elems, type `uint8`, 61440000 bytes (58.59375 Mb)\n",
      "trainPaths               list          n=3\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 341s 114s/step - loss: 3.3519 - acc: 0.7409\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 480s 160s/step - loss: 2.8235 - acc: 0.4211\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=1);\n",
    "\n",
    "model2Conv.fit(trainData, trainLabels, epochs=10,callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.save('networkModels/FCN-None-None-conv5.h5')\n",
    "model2Conv.save('networkModels/FCN-1600-1600-conv5-conv5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/XimeaT_20170613.mat\n",
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170531.mat\n",
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170622.mat\n",
      "Printed /Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/testLabelPredict/FIP_20170802.mat\n"
     ]
    }
   ],
   "source": [
    "basePath = '/Volumes/mac_jannic_2017/thanujan/Datasets/xFcnClassifier/';\n",
    "\n",
    "inPath1 = basePath + 'testData/Ximea_Tamron/20170613/Band';\n",
    "outpath1 = basePath + 'testLabelPredict/XimeaT_20170613.mat';\n",
    "inPath2 = basePath + 'testData/FIP/20170531/Band';\n",
    "outpath2 = basePath + 'testLabelPredict/FIP_20170531.mat';\n",
    "inPath3 = basePath + 'testData/FIP/20170622/Band';\n",
    "outpath3 = basePath + 'testLabelPredict/FIP_20170622.mat';\n",
    "inPath4 = basePath + 'testData/FIP/20170802/Band';\n",
    "outpath4 = basePath + 'testLabelPredict/FIP_20170802.mat';\n",
    "\n",
    "trainPaths = [[inPath1,outpath1],[inPath2,outpath2],[inPath3,outpath3],[inPath4,outpath4]];\n",
    "\n",
    "#predictAndPlotSet(trainPaths, model2Conv);\n",
    "predictAndSaveSet(trainPaths, model2Conv);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = plt.imshow(trainData[2,:,:,9]);\n",
    "plt.show()\n",
    "print(trainData[1,20,20,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-7de825006ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2Conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model2Conv.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jveith/anaconda/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "import pydot_ng as pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "plot_model(model2Conv, to_file='model2Conv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dot': '/Users/jveith/anaconda/bin/dot', 'twopi': '/Users/jveith/anaconda/bin/twopi', 'neato': '/Users/jveith/anaconda/bin/neato', 'circo': '/Users/jveith/anaconda/bin/circo', 'fdp': '/Users/jveith/anaconda/bin/fdp', 'sfdp': '/Users/jveith/anaconda/bin/sfdp'}\n"
     ]
    }
   ],
   "source": [
    "import pydot_ng as pydot\n",
    "import graphviz\n",
    "print(pydot.find_graphviz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FileName.pdf'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "dot = graphviz.Digraph(comment='The Round Table')\n",
    "\n",
    "dot.node('A', 'King Arthur')\n",
    "dot.node('B', 'Sir Bedevere the Wise')\n",
    "dot.node('L', 'Sir Lancelot the Brave')\n",
    "dot.edges(['AB', 'AL'])\n",
    "dot.edge('B', 'L', constraint='false')\n",
    "\n",
    "dot.render('FileName', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
